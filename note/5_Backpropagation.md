# 오차역전파법 (Backpropagation)

## 정의 및 목적

앞서서 Loss Function을 학습시킬 때, 우리는 신경망의 weight의 기울기에 수치미분을 적용하였다.

수치 미분은 단순하고 구현하기도 쉬운 장점이 있다.
하지만 계산시간이 오래걸린다는 단점이 존재한다.

이번 챕터에서는 weight를 효율적으로 계산하는 방법인 Backpropagation을 공부하자.

## 계산 그래프

<img src="../image/computational_graph.png">

계산 그래프는 계산과정을 그래프로 표현한 것이다. 굉장히 직관적이며, 처음에는 신경망의 연산과 변화율에 대한 연관성을 캐치하기 쉽다.

계산그래프는 복잡한 연산을 진행할 때 위력을 가진다. **"국소적인 계산"** 을 전파함으로써 최종 결과를 얻는다는 장점이 있다. **"국소적인 계산"** 을 통해 전체에서 어떤일이 일어나든 상관없이, 자신과 관계된 정보만을 결과로 출력할 수 있다는 것이 장점이다.
